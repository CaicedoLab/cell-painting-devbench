{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aabcd6-c79e-4f03-9dcb-9a51085258f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7c08c-2249-4fed-864d-812b88562782",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/scr/data/LINCS/DP-project/outputs/max_concentration_set/SQ00015128/A07/8/1@516.1053445229701x147.44633392226152.png\"\n",
    "img = skimage.io.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3869e-8753-4990-8a62-a02b8bc7b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd46e0-771d-45b3-9958-c8e0c771d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_channels(image, channel_width, mode=\"ignore\"):\n",
    "    # Expected input image shape: (h, w * c)\n",
    "    # Output image shape: (h, w, c)\n",
    "    output = np.reshape(image, (image.shape[0], channel_width, -1), order=\"F\")\n",
    "\n",
    "    if mode == \"ignore\":\n",
    "        # Keep all channels\n",
    "        pass\n",
    "    elif mode == \"drop\":\n",
    "        # Drop mask channel (last)\n",
    "        output = output[:, :, 0:-1]\n",
    "    elif mode == \"apply\":\n",
    "        # Use last channel as a binary mask\n",
    "        mask = output[\"image\"][:, :, -1:]\n",
    "        output = output[:, :, 0:-1] * mask\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59b0543-6e76-4419-a102-5c64fddf1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = fold_channels(img, img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba37e1b-6d09-4e5b-a533-f786ae56bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fold[:,:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8780129d-c4ab-492d-9857-0317c7862aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_to_rgb(channel):\n",
    "    px = np.concatenate(\n",
    "        (channel[np.newaxis, :, :], channel[np.newaxis, :, :], channel[np.newaxis, :, :]),\n",
    "        axis=0)\n",
    "    tensor = torch.Tensor(px)[None, ...]\n",
    "    normalized_tensor = v2.functional.normalize(tensor, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0816ed-4d32-41a7-8530-09239bc5b920",
   "metadata": {},
   "source": [
    "# Load the ViT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf5be7-bb9b-4cb4-9ded-e710472e2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "gpu = 5\n",
    "device = f\"cuda:{gpu}\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "dinov2_vits14_reg = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14_reg')\n",
    "dinov2_vits14_reg.eval()\n",
    "dinov2_vits14_reg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ffee9-64e3-4ef1-8535-bbf04e6ff786",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape, fold.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b9665-4ea9-4a83-aa40-fa18c73cdb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = torch.cat([channel_to_rgb(fold[17:-17,17:-17,i]) for i in range(5)])\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99846bbd-acc0-4f51-8f37-65ec78c3be4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dinov2_vits14_reg.forward_features(image_batch.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece9f67-b2d7-44b3-af43-a4eda8e027e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = output[\"x_norm_clstoken\"].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83072df8-5a9d-49a0-a65d-357cfcf2d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5fbc62-b70a-403a-b87a-179e6a3d3611",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"features.npz\", features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250b22f-f5a0-47f9-9564-420f6f9ecfcf",
   "metadata": {},
   "source": [
    "# Compress all image feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8695df-d797-4626-8a3c-020ece3f5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/scr/data/LINCS/DP-project/outputs/max_concentration_set\"\n",
    "csv_path = os.path.join(base_path, \"sc-metadata.csv\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for i, img_rel_path in enumerate(df['Image_Name']):\n",
    "    img_path = os.path.join(base_path, img_rel_path)\n",
    "    try:\n",
    "        img = skimage.io.imread(img_path)\n",
    "        fold = fold_channels(img, img.shape[0])\n",
    "        image_batch = torch.cat([channel_to_rgb(fold[17:-17, 17:-17, j]) for j in range(5)])\n",
    "        output = dinov2_vits14_reg.forward_features(image_batch.to(device))\n",
    "        features = output[\"x_norm_clstoken\"].cpu().detach().numpy()\n",
    "        all_features.append(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "if all_features:\n",
    "    all_features = np.concatenate(all_features, axis=0)\n",
    "    np.savez_compressed(\"features_test_50.npz\", all_features)\n",
    "else:\n",
    "    print(\"No features were extracted. Please check the paths and image processing steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59efc0-329a-48c1-82f8-6adccb62f8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d44eb-f38d-4b0a-8f87-6985b33e2964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
